{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "n_features = 28 * 28\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, n_features) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, n_features) / 255.\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name='kernel')\n",
    "        b = tf.Variable(tf.zeros([n_neurons], name='bias'))\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z\n",
    "\n",
    "\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_features), name='y')\n",
    "y = tf.placeholder(tf.int32,shape=(None), name='y')\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "#    hidden1 = tf.layers.dense(X, n_hidden1, name='hidden1', activation=tf.nn.relu)\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name='hidden1', activation=tf.nn.relu)\n",
    "#    hidden2 = tf.layers.dense(hidden1, n_hidden2, name='hidden2', activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name='hidden2', activation=tf.nn.relu)\n",
    "#    logits = tf.layers.dense(hidden2, n_outputs, name='outputs')\n",
    "    logits = neuron_layer(hidden2, n_outputs, name='outputs')\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='mean')\n",
    "    \n",
    "learning_rate = 0.01\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "file_writer.close()\n",
    "# tensorboard --logdir tf_logs/\n",
    "# localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch accuracy 0 Train 0.91253334 Test 0.9169\n",
      "Epoch accuracy 1 Train 0.9323 Test 0.9332\n",
      "Epoch accuracy 2 Train 0.94015 Test 0.9405\n",
      "Epoch accuracy 3 Train 0.94918334 Test 0.9467\n",
      "Epoch accuracy 4 Train 0.9546 Test 0.9505\n",
      "Epoch accuracy 5 Train 0.95865 Test 0.9555\n",
      "Epoch accuracy 6 Train 0.96293336 Test 0.9575\n",
      "Epoch accuracy 7 Train 0.9659333 Test 0.9594\n",
      "Epoch accuracy 8 Train 0.9687167 Test 0.9621\n",
      "Epoch accuracy 9 Train 0.97061664 Test 0.9639\n",
      "Epoch accuracy 10 Train 0.97263336 Test 0.9662\n",
      "Epoch accuracy 11 Train 0.97471666 Test 0.9673\n",
      "Epoch accuracy 12 Train 0.97651666 Test 0.9685\n",
      "Epoch accuracy 13 Train 0.9777833 Test 0.9688\n",
      "Epoch accuracy 14 Train 0.97713333 Test 0.9661\n",
      "Epoch accuracy 15 Train 0.98005 Test 0.9699\n",
      "Epoch accuracy 16 Train 0.9817333 Test 0.9709\n",
      "Epoch accuracy 17 Train 0.9831 Test 0.9714\n",
      "Epoch accuracy 18 Train 0.9834667 Test 0.9713\n",
      "Epoch accuracy 19 Train 0.98255 Test 0.972\n",
      "Epoch accuracy 20 Train 0.98501664 Test 0.972\n",
      "Epoch accuracy 21 Train 0.9860333 Test 0.9733\n",
      "Epoch accuracy 22 Train 0.9863667 Test 0.973\n",
      "Epoch accuracy 23 Train 0.9878167 Test 0.9741\n",
      "Epoch accuracy 24 Train 0.9880667 Test 0.974\n",
      "Epoch accuracy 25 Train 0.9894 Test 0.975\n",
      "Epoch accuracy 26 Train 0.98995 Test 0.9735\n",
      "Epoch accuracy 27 Train 0.99035 Test 0.9737\n",
      "Epoch accuracy 28 Train 0.99118334 Test 0.9751\n",
      "Epoch accuracy 29 Train 0.9908 Test 0.9752\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_yepochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print('Epoch accuracy', epoch, 'Train', acc_train, 'Test', acc_test)\n",
    "    saver.save(sess, './my_model_final.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './my_model_final.ckpt')\n",
    "    Z = logits.eval(feed_dict={X: X_test[:20]})\n",
    "\n",
    "y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4]\n",
      "Actual classes:    [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted classes:\", y_pred)\n",
    "print(\"Actual classes:   \", y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
